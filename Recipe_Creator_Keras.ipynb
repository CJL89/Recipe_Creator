{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependecies:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gensim.models as gs\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "from numpy import array\n",
    "import keras\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, GlobalMaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuring Notebook environment:\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 7.5)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients_vector</th>\n",
       "      <th>instructions_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p3pKOD6jIHEcjf20CCXohP8uqkG5dGi</th>\n",
       "      <td>grammie hamblets deviled crab</td>\n",
       "      <td>celery finely chopped green pepper finely chop...</td>\n",
       "      <td>toss ingredients lightly spoon buttered baking...</td>\n",
       "      <td>['celery', 'finely', 'chopped', 'green', 'pepp...</td>\n",
       "      <td>['toss', 'ingredients', 'lightly', 'spoon', 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO</th>\n",
       "      <td>infineon raceway baked beans</td>\n",
       "      <td>skirt steak cut inch dicekosher salt fresh cra...</td>\n",
       "      <td>watch make recipe sprinkle steak salt pepper s...</td>\n",
       "      <td>['skirt', 'steak', 'cut', 'inch', 'dicekosher'...</td>\n",
       "      <td>['watch', 'make', 'recipe', 'sprinkle', 'steak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK</th>\n",
       "      <td>southwestern black bean dip</td>\n",
       "      <td>cups dried black beans picked rinsed cups wate...</td>\n",
       "      <td>saucepan let beans soak enough cold water cove...</td>\n",
       "      <td>['cups', 'dried', 'black', 'beans', 'picked', ...</td>\n",
       "      <td>['saucepan', 'let', 'beans', 'soak', 'enough',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5l1yTSYFifF/M2dfbD6DX28WWQpLWNK</th>\n",
       "      <td>sour cream noodle bake</td>\n",
       "      <td>ground chuckone tomato sauce saltfreshly groun...</td>\n",
       "      <td>watch make recipe preheat oven degrees f brown...</td>\n",
       "      <td>['ground', 'chuckone', 'tomato', 'sauce', 'sal...</td>\n",
       "      <td>['watch', 'make', 'recipe', 'preheat', 'oven',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kRBQSWtqYWqtkb34FGeenBSbC32gIdO</th>\n",
       "      <td>sushi renovation</td>\n",
       "      <td>rice brown mediumgrain cookedcup quinoacup swe...</td>\n",
       "      <td>special equipment sushi mat cook brown rice qu...</td>\n",
       "      <td>['rice', 'brown', 'mediumgrain', 'cookedcup', ...</td>\n",
       "      <td>['special', 'equipment', 'sushi', 'mat', 'cook...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         title  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  grammie hamblets deviled crab   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO   infineon raceway baked beans   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK    southwestern black bean dip   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK         sour cream noodle bake   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO               sushi renovation   \n",
       "\n",
       "                                                                       ingredients  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  celery finely chopped green pepper finely chop...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  skirt steak cut inch dicekosher salt fresh cra...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  cups dried black beans picked rinsed cups wate...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ground chuckone tomato sauce saltfreshly groun...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  rice brown mediumgrain cookedcup quinoacup swe...   \n",
       "\n",
       "                                                                      instructions  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  toss ingredients lightly spoon buttered baking...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  watch make recipe sprinkle steak salt pepper s...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  saucepan let beans soak enough cold water cove...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  watch make recipe preheat oven degrees f brown...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  special equipment sushi mat cook brown rice qu...   \n",
       "\n",
       "                                                                ingredients_vector  \\\n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  ['celery', 'finely', 'chopped', 'green', 'pepp...   \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  ['skirt', 'steak', 'cut', 'inch', 'dicekosher'...   \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  ['cups', 'dried', 'black', 'beans', 'picked', ...   \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ['ground', 'chuckone', 'tomato', 'sauce', 'sal...   \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  ['rice', 'brown', 'mediumgrain', 'cookedcup', ...   \n",
       "\n",
       "                                                               instructions_vector  \n",
       "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi  ['toss', 'ingredients', 'lightly', 'spoon', 'b...  \n",
       "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO  ['watch', 'make', 'recipe', 'sprinkle', 'steak...  \n",
       "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK  ['saucepan', 'let', 'beans', 'soak', 'enough',...  \n",
       "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK  ['watch', 'make', 'recipe', 'preheat', 'oven',...  \n",
       "kRBQSWtqYWqtkb34FGeenBSbC32gIdO  ['special', 'equipment', 'sushi', 'mat', 'cook...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/strings/df_clean.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_vector'] = gs.Word2Vec(df['ingredients_vector'], min_count=1, size= 50, workers=3, window=3, sg=1)\n",
    "df['instructions_vector'] = gs.Word2Vec(df['instructions_vector'], min_count=1, size= 50, workers=3, window=3, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p3pKOD6jIHEcjf20CCXohP8uqkG5dGi    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "S7aeOIrsrgT0jLP32jKGg4j.o9zi2DO    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "o9MItV9txfoPsUQ4v8b0vh1.VdjwfsK    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "5l1yTSYFifF/M2dfbD6DX28WWQpLWNK    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "kRBQSWtqYWqtkb34FGeenBSbC32gIdO    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "                                                      ...                     \n",
      "4bfMWxlbKhx/McJq/89k0SBdw.VvAzW    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "T8lWBA1fcVdjxhMSWuoAbGoy5Lj.A8m    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "f/coffo2TMs2J2gq5nTOUIqH2TRAkui    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "q3aDJc4zoEF5QT4e7Mn.ieQwV.DyHwS    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "7cXA77UpdDtIfBug2v6lEVIuV3Zcvhm    Word2Vec(vocab=56508, size=50, alpha=0.025)\n",
      "Name: ingredients_vector, Length: 59612, dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'most_similar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9e22aede36ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ingredients_vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ingredients_vector'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'chicken'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/envs/Springboard/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5179\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5180\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'most_similar'"
     ]
    }
   ],
   "source": [
    "print(df['ingredients_vector'])\n",
    "data = df['ingredients_vector'].most_similar('chicken')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tokenized.drop('title', axis=1)\n",
    "y = df_tokenized['title'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=1000)\n",
    "# x_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "# x_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
